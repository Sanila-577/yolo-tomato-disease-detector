# ğŸŒ± Plant RAG Chatbot (LangGraph + FAISS + Streamlit)

An intelligent Retrieval-Augmented Generation (RAG) chatbot for answering plant-related questions using PDF knowledge, web search fallback, and multi-agent reasoning built with LangGraph, LangChain, FAISS, and Streamlit.

---

## ğŸš€ Features
- ğŸ§  Multi-Agent Architecture (LangGraph)
- Router Agent (Chat / RAG / Web)
- RAG Agent (FAISS Vector Search)
- Web Agent (Tavily Search)
- Grader Agent (Context relevance checking)
- ğŸ“š RAG over PDFs from `context/`
- FAISS for semantic similarity search
- HuggingFace embeddings (`all-MiniLM-L6-v2`)
- ğŸŒ Web Search Fallback (Tavily)
- ğŸ’¬ Conversational memory with LangChain messages
- ğŸ–¥ï¸ Streamlit UI
ğŸŒ± Plant RAG Chatbot (LangGraph + FAISS + Streamlit)
---

## ğŸ“ Project Structure

```
RAG-chatbot/
â”œâ”€ context/                     # PDF documents for RAG
â”œâ”€ faiss_db/                    # Persistent FAISS index storage
â”‚  â””â”€ index.faiss               # Auto-generated on first run
â”œâ”€ agents/                      # Agent logic
â”‚  â”œâ”€ router_agent.py
â”‚  â”œâ”€ chat_agent.py
â”‚  â”œâ”€ retriever_agent.py
â”‚  â”œâ”€ web_agent.py
â”‚  â””â”€ grader_answer_agent.py
â”œâ”€ tools/                       # Tool definitions
â”‚  â”œâ”€ retriever_tool.py
â”‚  â””â”€ tavily_search_tool.py
â”œâ”€ core/                        # Graph construction and execution
â”‚  â”œâ”€ build_graph.py
â”‚  â”œâ”€ faiss_setup.py
â”‚  â”œâ”€ llm.py
â”‚  â””â”€ run_agent.py
â”œâ”€ streamlit_app.py             # Streamlit frontend
â”œâ”€ requirements.txt
â”œâ”€ .env                         # Create this
â””â”€ readme.md
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone or open the project
If cloning from Git:

```bash
git clone <your-repo-url>
cd RAG-chatbot
```

### 2ï¸âƒ£ Create and activate a virtual environment

```bash
python -m venv .venv
source .venv/bin/activate        # macOS / Linux
# venv\Scripts\activate         # Windows (PowerShell)
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Environment Variables
Create a `.env` file in the project root:

```env
OPENROUTER_API_KEY=your_openrouter_api_key
TAVILY_API_KEY=your_tavily_api_key
```

Notes:
- LLM configured via OpenRouter in `core/llm.py` using model `openai/gpt-4o-mini`.
- Tavily is used for web search fallback; an API key is required.

---

## ğŸ“š PDF Knowledge Base
- Place your plant-related PDFs inside `context/`.
- On first run, FAISS embeddings are created automatically from PDFs using `all-MiniLM-L6-v2`.
- Subsequent runs load the vector store from `faiss_db/` (no re-embedding).

---

## â–¶ï¸ Running the Application

### ğŸ–¥ï¸ Streamlit UI (Recommended)
```bash
streamlit run streamlit_app.py
```
Open: http://localhost:8501

### ğŸ’» Terminal Version (Optional)
```bash
python -m core.run_agent
```

---

## ğŸ§  How It Works

### 1ï¸âƒ£ Router Agent
Classifies the query into:
- `chat` â†’ casual conversation
- `rag` â†’ plant knowledge from PDFs
- `web` â†’ general knowledge via Tavily

### 2ï¸âƒ£ RAG Agent
- Uses FAISS to retrieve relevant document chunks
- Calls the retriever tool
- Stores retrieved content for grading

### 3ï¸âƒ£ Grader + Answer
- Evaluates whether retrieved context fully answers the question
- If insufficient, triggers web fallback
- If sufficient, generates final answer

### 4ï¸âƒ£ Web Agent (Fallback)
- Uses Tavily search for live web information
- Returns answers when local knowledge is insufficient

---

## ğŸ§ª Tech Stack
- LangGraph â€“ Multi-agent workflow orchestration
- LangChain â€“ Tool calling & message handling
- FAISS â€“ Vector similarity search
- HuggingFace Embeddings (`all-MiniLM-L6-v2`)
- OpenRouter (model: `openai/gpt-4o-mini`)
- Tavily API â€“ Web search
- Streamlit â€“ Frontend UI

---

## âœ… Example Queries
- What are common tomato plant diseases?
- How to treat leaf curl in tomatoes?
- What is nitrogen deficiency in plants?
- Hello!
- Latest research on plant fungal infections

---

## ğŸ”’ Notes
- FAISS index persists between runs (stored in `faiss_db/`)
- Chat memory resets on Streamlit refresh
- Designed for modular expansion (tools, agents, memory)

## ğŸ› ï¸ Troubleshooting
- If FAISS build fails, ensure PDFs exist in `context/` and retry.
- If OpenRouter requests fail, check `OPENROUTER_API_KEY` and network access.
- For Tavily errors, verify `TAVILY_API_KEY` and reduce `max_results` in `tools/tavily_search_tool.py` if rate limited.

---

## ğŸ§‘â€ğŸ’» Author
Built with â¤ï¸ using LangGraph + RAG. Feel free to fork, extend, and deploy ğŸš€

---

## Extras
If you want, I can also:
- Add architecture diagrams
- Write deployment instructions (Docker / AWS)
- Add example screenshots
- Convert this into a research-grade README

An intelligent Retrieval-Augmented Generation (RAG) chatbot for answering plant-related questions using PDF knowledge, web search fallback, and multi-agent reasoning built with LangGraph, LangChain, FAISS, and Streamlit.

â¸»

ğŸš€ Features
	â€¢	ğŸ§  Multi-Agent Architecture (LangGraph)
	â€¢	Router Agent (Chat / RAG / Web)
	â€¢	RAG Agent (FAISS Vector Search)
	â€¢	Web Agent (Tavily Search)
	â€¢	Grader Agent (Context relevance checking)
	â€¢	ğŸ“š RAG over PDFs
	â€¢	Loads plant-related PDFs from context/
	â€¢	Uses FAISS for semantic similarity search
	â€¢	HuggingFace embeddings (all-MiniLM-L6-v2)
	â€¢	ğŸŒ Web Search Fallback
	â€¢	Automatically falls back to Tavily web search when local context is insufficient
	â€¢	ğŸ’¬ Conversational Memory
	â€¢	Maintains multi-turn conversation using LangChain message objects
	â€¢	ğŸ–¥ï¸ Streamlit UI
	â€¢	Interactive chat interface
	â€¢	Session-based memory
	â€¢	Clean user/bot message separation

â¸»

ğŸ“ Project Structure

rag_chatbot/
â”‚
â”œâ”€ context/                     # PDF documents for RAG
â”‚   â”œâ”€ tomato_diseases.pdf
â”‚   â””â”€ plant_guide.pdf
â”‚
â”œâ”€ faiss_db/                    # Persistent FAISS index storage
â”‚   â””â”€ (FAISS files auto-generated)
â”‚
â”œâ”€ agents/                      # Agent logic
â”‚   â”œâ”€ router_agent.py
â”‚   â”œâ”€ chat_agent.py
â”‚   â”œâ”€ retriever_agent.py
â”‚   â”œâ”€ web_agent.py
â”‚   â””â”€ grader_agent.py
â”‚
â”œâ”€ tools/                       # Tool definitions
â”‚   â”œâ”€ retriever_tool.py
â”‚   â””â”€ tavily_search_tool.py
â”‚
â”œâ”€ core/                        # Graph construction and execution
â”‚   â”œâ”€ build_graph.py
â”‚   â””â”€ run_agent.py
â”‚
â”œâ”€ streamlit_app.py             # Streamlit frontend
â”œâ”€ requirements.txt
â”œâ”€ .env
â””â”€ README.md


â¸»

âš™ï¸ Setup Instructions

1ï¸âƒ£ Clone the repository

git clone https://github.com/your-username/rag-chatbot.git
cd rag-chatbot


â¸»

2ï¸âƒ£ Create and activate a virtual environment

python -m venv venv
source venv/bin/activate        # macOS / Linux
venv\Scripts\activate           # Windows


â¸»

3ï¸âƒ£ Install dependencies

pip install -r requirements.txt


â¸»

4ï¸âƒ£ Environment Variables

Create a .env file in the root directory:

OPENROUTER_API_KEY=your_openrouter_api_key
TAVILY_API_KEY=your_tavily_api_key


â¸»

ğŸ“š PDF Knowledge Base
	â€¢	Place your plant-related PDFs inside the context/ folder.
	â€¢	On first run, FAISS embeddings are created automatically.
	â€¢	On subsequent runs, the vector store is loaded from faiss_db/ (no re-embedding).

â¸»

â–¶ï¸ Running the Application

ğŸ–¥ï¸ Streamlit UI (Recommended)

streamlit run streamlit_app.py

Then open:

http://localhost:8501


â¸»

ğŸ’» Terminal Version (Optional)

python core/run_agent.py


â¸»

ğŸ§  How It Works

1ï¸âƒ£ Router Agent

Determines whether the query is:
	â€¢	chat â†’ casual conversation
	â€¢	rag â†’ plant knowledge from PDFs
	â€¢	web â†’ general knowledge via Tavily

â¸»

2ï¸âƒ£ RAG Agent
	â€¢	Uses FAISS to retrieve relevant document chunks
	â€¢	Calls retriever tool dynamically
	â€¢	Stores retrieved content for grading

â¸»

3ï¸âƒ£ Grader Agent
	â€¢	Evaluates whether retrieved context fully answers the question
	â€¢	If insufficient, triggers web fallback
	â€¢	If sufficient, generates final answer

â¸»

4ï¸âƒ£ Web Agent (Fallback)
	â€¢	Uses Tavily search for live web information
	â€¢	Returns answers when local knowledge is insufficient

â¸»

ğŸ§ª Tech Stack
	â€¢	LangGraph â€“ Multi-agent workflow orchestration
	â€¢	LangChain â€“ Tool calling & message handling
	â€¢	FAISS â€“ Vector similarity search
	â€¢	HuggingFace Embeddings
	â€¢	OpenRouter (GPT-4o-mini)
	â€¢	Tavily API â€“ Web search
	â€¢	Streamlit â€“ Frontend UI

â¸»

âœ… Example Queries
	â€¢	What are common tomato plant diseases?
	â€¢	How to treat leaf curl in tomatoes?
	â€¢	What is nitrogen deficiency in plants?
	â€¢	Hello!
	â€¢	Latest research on plant fungal infections

â¸»

ğŸ”’ Notes
	â€¢	FAISS index persists between runs
	â€¢	Chat memory resets on Streamlit refresh
	â€¢	Designed for modular expansion (tools, agents, memory)

â¸»

ğŸ“Œ Future Enhancements
	â€¢	ğŸ” Streaming responses
	â€¢	ğŸ§  Conversation summarization memory
	â€¢	ğŸ—‚ï¸ Multi-collection FAISS support
	â€¢	â˜ï¸ Cloud deployment
	â€¢	ğŸ“Š Source citation UI

â¸»

ğŸ§‘â€ğŸ’» Author

Built with â¤ï¸ using LangGraph + RAG
Feel free to fork, extend, and deploy ğŸš€

â¸»

If you want, I can also:
	â€¢	Add architecture diagrams
	â€¢	Write deployment instructions (Docker / AWS)
	â€¢	Add example screenshots
	â€¢	Convert this into a research-grade README

Just tell me ğŸ‘