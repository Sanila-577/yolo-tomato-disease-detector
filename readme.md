# ğŸŒ± Neuro Leaf: Tomato Leaf Disease Assistant

FastAPI + LangGraph backend with a Streamlit frontend for tomato leaf disease detection and guidance. Runs YOLO-based vision to detect diseases, feeds the latest report into a LangGraph chat pipeline, and serves responses through a chat UI.

---

## ğŸ“¦ Whatâ€™s Inside

- FastAPI service (`api/main.py`) with routes:
  - `/detect` â€“ runs YOLO inference, returns annotated image + report
  - `/chat` â€“ LangGraph chat endpoint with per-session memory
  - `/health` â€“ basic health check
- Streamlit UI (`frontend/app.py`) for upload, detection preview, and chat
- LangGraph agents (`agents/`) for routing, RAG, web fallback, and grading
- Vision pipeline (`vision/`) and YOLO weights in `models/tomato_leaf_disease_detector_v1.pt`
- FAISS vector store in `faiss_db/` for RAG
- Shared state helpers in `frontend/state.py` for session IDs and caching

---

## ğŸ—‚ï¸ Project Structure (high level)

```
agents/                    # LangGraph agents
  â”œâ”€â”€ router_agent.py      # Routes queries (chat/RAG/web)
  â”œâ”€â”€ chat_agent.py        # Conversational agent
  â”œâ”€â”€ retriever_agent.py   # RAG retriever over FAISS
  â”œâ”€â”€ web_agent.py         # Web search fallback (Tavily)
  â”œâ”€â”€ grader_answer_agent.py # Grades answer relevance
  â”œâ”€â”€ state.py             # Agent state management
  â””â”€â”€ __init__.py
api/                       # FastAPI backend
  â”œâ”€â”€ main.py              # FastAPI app
  â”œâ”€â”€ routes/
  â”‚   â”œâ”€â”€ chat.py          # /chat endpoint
  â”‚   â”œâ”€â”€ detect.py        # /detect endpoint
  â”‚   â””â”€â”€ health.py        # /health endpoint
  â”œâ”€â”€ schemas/
  â”‚   â”œâ”€â”€ chat_schema.py
  â”‚   â””â”€â”€ vision_schema.py
  â”œâ”€â”€ static/outputs/      # Annotated images from detection
  â””â”€â”€ __init__.py
core/                      # Core logic & LangGraph
  â”œâ”€â”€ build_graph.py       # Construct LangGraph workflow
  â”œâ”€â”€ run_graph.py         # Execute graph
  â”œâ”€â”€ faiss_setup.py       # FAISS index initialization
  â”œâ”€â”€ llm.py               # LLM configuration
  â””â”€â”€ __init__.py
frontend/                  # Streamlit UI
  â”œâ”€â”€ app.py               # Main app entry
  â”œâ”€â”€ config.py            # Configuration
  â”œâ”€â”€ state.py             # Session state management
  â”œâ”€â”€ components/
  â”‚   â”œâ”€â”€ chat_ui.py       # Chat interface
  â”‚   â””â”€â”€ detection_view.py # Detection preview
  â”œâ”€â”€ services/
  â”‚   â”œâ”€â”€ chat_service.py  # Chat API calls
  â”‚   â””â”€â”€ detection_service.py # Detection API calls
  â””â”€â”€ __init__.py
vision/                    # YOLO inference
  â”œâ”€â”€ inference.py         # Run inference
  â”œâ”€â”€ model.py             # Model loading
  â”œâ”€â”€ utils.py             # Vision utilities
  â””â”€â”€ __init__.py
tools/                     # Tool integrations
  â”œâ”€â”€ retriever_tool.py    # FAISS retrieval
  â”œâ”€â”€ tavily_search_tool.py # Web search
  â””â”€â”€ __init__.py
models/                    # Pre-trained weights
  â””â”€â”€ tomato_leaf_disease_detector_v1.pt
faiss_db/                  # Vector store index
  â””â”€â”€ index.faiss
data/                      # Training data
  â””â”€â”€ dataset/             # Roboflow dataset (YOLO format)
      â”œâ”€â”€ train/
      â”œâ”€â”€ valid/
      â””â”€â”€ test/
static/outputs/            # Generated annotated images
docs/                      # Documentation
readme.md, requirements.txt
```

---

## ğŸ§° Prerequisites

- Python 3.10+ recommended
- Virtual environment (venv/conda)
- GPU optional; YOLO will run on CPU if CUDA is unavailable

Environment variables (create `.env` in project root):

```
OPENROUTER_API_KEY=your_key          # for LLM in core/llm.py
TAVILY_API_KEY=your_key              # for web fallback
```

---

## ğŸš€ Setup

```bash
python -m venv .venv
source .venv/bin/activate           # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

If you need the FAISS index fresh, delete `faiss_db/` and it will rebuild on first RAG call.

---

## â–¶ï¸ Run the stack

In one terminal (backend):

```bash
cd /Users/sanilawijesekara/Documents/RAG-chatbot
fastapi dev ./api/main.py           # or: uvicorn api.main:app --reload
```

In another terminal (frontend):

```bash
cd /Users/sanilawijesekara/Documents/RAG-chatbot
streamlit run ./frontend/app.py
```

Open Streamlit at http://localhost:8501 and upload a tomato leaf image.

---

## ğŸ§  How it works

1) Upload leaf image â†’ `/detect` returns annotated image + structured report
2) The latest report is stored per session and sent with the first chat turn
3) LangGraph routes: chat for small talk, RAG over FAISS for plant knowledge, web for out-of-domain
4) Chat memory resets when a new disease is detected; the UI still shows your previous messages for convenience

---

## ğŸ” Troubleshooting

- If detection fails: ensure the model file exists at `models/tomato_leaf_disease_detector_v1.pt` and the image is a valid JPG/PNG.
- If chat fails: confirm `fastapi dev ./api/main.py` is running and API_URL in frontend services points to the backend (defaults to 127.0.0.1:8000).
- For theme issues: UI styling is driven by `frontend/styles/theme.css`; adjust there if needed.

---

## ğŸ“„ License

MIT (update if your project uses a different license).
